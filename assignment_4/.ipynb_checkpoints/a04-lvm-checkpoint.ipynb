{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca410de",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import get_ipython\n",
    "from numpy.linalg import svd\n",
    "from util import nextplot, plot_xy\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# setup plotting\n",
    "import psutil\n",
    "inTerminal = not \"IPKernelApp\" in get_ipython().config\n",
    "inJupyterNb = any(filter(lambda x: x.endswith(\"jupyter-notebook\"), psutil.Process().parent().cmdline()))\n",
    "inJupyterLab = any(filter(lambda x: x.endswith(\"jupyter-lab\"), psutil.Process().parent().cmdline()))\n",
    "if not inJupyterLab:\n",
    "    from IPython import get_ipython\n",
    "    get_ipython().run_line_magic(\"matplotlib\", \"\" if inTerminal else \"notebook\" if inJupyterNb else \"widget\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19200ada",
   "metadata": {},
   "source": [
    "# 1 Probabilistic PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c7615a",
   "metadata": {},
   "source": [
    "## 1a) Toy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da7d4bf",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# You do not need to modify this method.\n",
    "def ppca_gen(N=10000, D=2, L=2, sigma2=0.5, mu=None, lambda_=None, Q=None, seed=None):\n",
    "    \"\"\"Generate data from a given PPCA model.\n",
    "\n",
    "    Unless specified otherwise, uses a fixed mean, fixed eigenvalues (variances along\n",
    "    principal components), and a random orthogonal eigenvectors (principal components).\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # determine model parameters (from arguments or default)\n",
    "    rng = np.random.RandomState(seed)\n",
    "    if mu is None:\n",
    "        mu = np.arange(D) + 1.0\n",
    "    if Q is None:\n",
    "        Q = scipy.stats.ortho_group.rvs(D, random_state=rng)\n",
    "    if lambda_ is None:\n",
    "        lambda_ = np.arange(D, 0, -1) * 2\n",
    "\n",
    "    # weight matrix is determined from first L eigenvectors and eigenvalues of\n",
    "    # covariance matrix\n",
    "    Q_L = Q[:, :L]\n",
    "    lambda_L = lambda_[:L]\n",
    "    W = Q_L * np.sqrt(lambda_L)  # scales columns\n",
    "\n",
    "    # generate data\n",
    "    Z = rng.standard_normal(size=(N, L))  # latent variables\n",
    "    Eps = rng.standard_normal(size=(N, D)) * np.sqrt(sigma2)  # noise\n",
    "    X = Z @ W.transpose() + mu + Eps  # data points\n",
    "\n",
    "    # all done\n",
    "    return dict(\n",
    "        N=N, D=D, L=L, X=X, Z=Z, mu=mu, Q_L=Q_L, lambda_L=lambda_L, W=W, Eps=Eps\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784a05ec",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# You do not need to modify this method.\n",
    "def ppca_plot_2d(data, X=\"X\", mu=\"mu\", W=\"W\", alpha=0.05, axis=None, **kwargs):\n",
    "    \"\"\"Plot 2D PPCA data along with its weight vectors.\"\"\"\n",
    "    if not axis:\n",
    "        nextplot()\n",
    "        axis = plt.gca()\n",
    "    X = data[X] if isinstance(X, str) else X\n",
    "    plot_xy(X[:, 0], X[:, 1], alpha=alpha, axis=axis, **kwargs)\n",
    "\n",
    "    # additional plot elements: mean and components\n",
    "    if mu is not None:\n",
    "        mu = data[mu] if isinstance(mu, str) else mu\n",
    "        if W is not None:\n",
    "            W = data[W] if isinstance(W, str) else W\n",
    "            head_width = np.linalg.norm(W[:, 0]) / 10.0\n",
    "            for j in range(W.shape[1]):\n",
    "                axis.arrow(\n",
    "                    mu[0],\n",
    "                    mu[1],\n",
    "                    W[0, j],\n",
    "                    W[1, j],\n",
    "                    length_includes_head=True,\n",
    "                    head_width=head_width,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb7ccbe",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate and plot a toy dataset\n",
    "toy_ppca = ppca_gen(L=1, sigma2=0.5, seed=0)\n",
    "ppca_plot_2d(toy_ppca)\n",
    "print(np.sum(toy_ppca[\"X\"] ** 3))  # must be 273244.3990646409"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dcf7f2",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Impact of noise\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971711fd",
   "metadata": {},
   "source": [
    "## 1b) Maximum Likelihood Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc31025",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ppca_mle(X, L):\n",
    "    \"\"\"Computes the ML estimates of PPCA model parameters.\n",
    "\n",
    "    Returns a dictionary with keys `mu`, `W`, and `sigma2` and the corresponding ML\n",
    "    estimates as values.\n",
    "\n",
    "    \"\"\"\n",
    "    N, D = X.shape\n",
    "\n",
    "    # Compute the ML estimates of the PPCA model parameters: mu_mle, sigma2_mle (based\n",
    "    # on mu_mle), and W_mle (based on mu_mle and sigma2_mle). In your code, only use\n",
    "    # standard matrix/vector operations and svd(...).\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    return dict(mu=mu_mle, W=W_mle, sigma2=sigma2_mle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9650590",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test your solution. This should produce:\n",
    "# {'mu': array([0.96935329, 1.98309575]),\n",
    "#  'W': array([[-1.72988776], [-0.95974566]]),\n",
    "#  'sigma2': 0.4838656103694303}\n",
    "ppca_mle(toy_ppca[\"X\"], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948c42c5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test your solution. This should produce:\n",
    "# {'mu': array([0.96935329, 1.98309575]),\n",
    " # 'W': array([[-1.83371058,  0.33746522], [-1.0173468 , -0.60826214]]),\n",
    " # 'sigma2': 0.0}\n",
    "ppca_mle(toy_ppca[\"X\"], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4f3c74",
   "metadata": {},
   "source": [
    "## 1c) Negative Log-Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abe32a0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ppca_nll(X, model):\n",
    "    \"\"\"Compute the negative log-likelihood for the given data.\n",
    "\n",
    "    Model is a dictionary containing keys \"mu\", \"sigma2\" and \"W\" (as produced by\n",
    "    `ppca_mle` above).\n",
    "\n",
    "    \"\"\"\n",
    "    N, D = X.shape\n",
    "\n",
    "    # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df09d8df",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test your solution. This should produce: 32154.198760474777\n",
    "ppca_nll(toy_ppca[\"X\"], ppca_mle(toy_ppca[\"X\"], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accd0f57",
   "metadata": {},
   "source": [
    "## 1d) Discover the Secret!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adbc403",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the secret data\n",
    "X = np.loadtxt(\"data/secret_ppca.csv\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30b711d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Determine a suitable choice of L using a scree plot.\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719ef598",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Determine a suitable choice of L using validation data.\n",
    "split = len(X) * 3 // 4\n",
    "X_train = X[:split,]\n",
    "X_valid = X[split:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45713bc",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c5e6cc",
   "metadata": {},
   "source": [
    "# 2 Gaussian Mixture Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0318cb10",
   "metadata": {},
   "source": [
    "## 2a) Toy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39ad9e6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# You do not need to modify this function.\n",
    "def gmm_gen(N, mu, pi, Sigma=None, seed=None):\n",
    "    \"\"\"Generate data from a given GMM model.\n",
    "\n",
    "    `N` is the number of data points to generate. `mu` and `Sigma` are lists with `K`\n",
    "    elements holding the mean and covariance matrix of each mixture component. `pi` is a\n",
    "    `K`-dimensional probability vector of component sizes.\n",
    "\n",
    "    If `Sigma` is unspecified, a default (random) choice is taken.\n",
    "    \"\"\"\n",
    "    K = len(pi)\n",
    "    D = len(mu[0])\n",
    "    rng = np.random.RandomState(seed)\n",
    "    if Sigma is None:\n",
    "        Sigma = [\n",
    "            Q.transpose() @ np.diag([(k + 1) ** 2, k + 1]) @ Q\n",
    "            for k, Q in enumerate([scipy.stats.ortho_group.rvs(2, random_state=rng) for k in range(K)])\n",
    "        ]\n",
    "\n",
    "    components = rng.choice(range(K), p=pi, size=N)\n",
    "    X = np.zeros([N, D])\n",
    "    for k in range(K):\n",
    "        indexes = components == k\n",
    "        N_k = np.sum(indexes.astype(np.int_))\n",
    "        if N_k == 0:\n",
    "            continue\n",
    "\n",
    "        dist = scipy.stats.multivariate_normal(mean=mu[k], cov=Sigma[k], seed=rng)\n",
    "        X[indexes, :] = dist.rvs(size=N_k)\n",
    "\n",
    "    return dict(X=X, components=components, mu=mu, Sigma=Sigma, pi=pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c4fb65",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate a toy dataset and plot it.\n",
    "toy_gmm = gmm_gen(\n",
    "    10000,\n",
    "    [\n",
    "        np.array([0, 0]),\n",
    "        np.array([10, 0]),\n",
    "        np.array([-10, 0]),\n",
    "        np.array([0, 10]),\n",
    "        np.array([0, -10]),\n",
    "    ],\n",
    "    np.array([0.1, 0.2, 0.25, 0.1, 0.35]),\n",
    "    seed=4,\n",
    ")\n",
    "\n",
    "print(np.sum(toy_gmm[\"X\"] ** 3))  # must be -4380876.753061278\n",
    "\n",
    "plot_xy(toy_gmm[\"X\"][:, 0], toy_gmm[\"X\"][:, 1], toy_gmm[\"components\"], alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc82158",
   "metadata": {},
   "source": [
    "## 2b) K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542f8ad8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fit 5 clusters using k-means.\n",
    "kmeans = KMeans(5).fit(toy_gmm[\"X\"])\n",
    "plot_xy(toy_gmm[\"X\"][:, 0], toy_gmm[\"X\"][:, 1], kmeans.labels_, alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52535bbf",
   "metadata": {},
   "source": [
    "## 2c) Fit a GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f759ea",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gmm_e(X, model, return_F=False):\n",
    "    \"\"\"Perform the E step of EM for a GMM (MLE estimate).\n",
    "\n",
    "    `model` is a dictionary holding model parameters (keys `mu`, `Sigma`, and `pi`\n",
    "    defined as in `gmm_gen`).\n",
    "\n",
    "    Returns a NxK matrix of cluster membership probabilities. If `return_F` is true,\n",
    "    also returns an NxK matrix holding the density of each data point (row) for each\n",
    "    component (column).\n",
    "\n",
    "    \"\"\"\n",
    "    mu, Sigma, pi = model[\"mu\"], model[\"Sigma\"], model[\"pi\"]\n",
    "    N, D = X.shape\n",
    "    K = len(pi)\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    # all done\n",
    "    if return_F:\n",
    "        return W, F\n",
    "    else:\n",
    "        return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91aa9dfd",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test your solution. This should produce:\n",
    "# (array([[9.99999999e-01, 8.65221693e-10, 1.59675131e-23, 1.14015011e-41, 2.78010004e-65],\n",
    "        # [1.00000000e+00, 3.75078862e-12, 1.55035521e-23, 1.28102693e-34, 1.86750812e-46],\n",
    "        # [9.99931809e-01, 6.81161224e-05, 7.23302032e-08, 2.17176125e-09, 1.62736835e-10]]),\n",
    " # array([[1.71811600e-08, 5.94620494e-18, 1.82893598e-31, 9.79455071e-50, 1.59217812e-73],\n",
    "        # [1.44159783e-15, 2.16285148e-27, 1.48999246e-38, 9.23362817e-50, 8.97398547e-62],\n",
    "        # [1.85095927e-09, 5.04355064e-14, 8.92595932e-17, 2.01005787e-18, 1.00413265e-19]]))\n",
    "dummy_model = dict(\n",
    "    mu=[np.array([k, k + 1]) for k in range(5)],\n",
    "    Sigma=[np.array([[3, 1], [1, 2]]) / (k + 1) for k in range(5)],\n",
    "    pi=np.array([0.1, 0.25, 0.15, 0.2, 0.3]),\n",
    ")\n",
    "gmm_e(toy_gmm[\"X\"][:3,], dummy_model, return_F=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025df89a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gmm_m(X, W):\n",
    "    \"\"\"Perform the M step of EM for a GMM (MLE estimate).\n",
    "\n",
    "    `W` is the NxK cluster membership matrix computed in the E step. Returns a new model\n",
    "    (dictionary with keys `mu`, `Sigma`, and `pi` defined as in `gmm_gen`).\n",
    "\n",
    "    \"\"\"\n",
    "    N, D = X.shape\n",
    "    K = W.shape[1]\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    return dict(mu=mu, Sigma=Sigma, pi=pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f8db98",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test your solution. This should produce:\n",
    "# {'mu': [array([ 6.70641574, -0.47971125]),\n",
    "#   array([8.2353509 , 2.52134815]),\n",
    "#   array([-3.0476848 , -1.70722161])],\n",
    "#  'Sigma': [array([[88.09488652, 11.08635139],\n",
    "#          [11.08635139,  1.39516823]]),\n",
    "#   array([[45.82761873, 11.38773232],\n",
    "#          [11.38773232,  6.87352224]]),\n",
    "#   array([[98.6662729 , 12.41671355],\n",
    "#          [12.41671355,  1.56258842]])],\n",
    "#  'pi': array([0.13333333, 0.53333333, 0.33333333])}\n",
    "gmm_m(toy_gmm[\"X\"][:3,], np.array([[0.1, 0.2, 0.7], [0.3, 0.4, 0.3], [0.0, 1.0, 0.0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af4c772",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# you do not need to modify this method\n",
    "def gmm_fit(X, K, max_iter=100, mu0=None, Sigma0=None, pi0=None, gmm_m=gmm_m):\n",
    "    \"\"\"Fit a GMM model using EM.\n",
    "\n",
    "    `K` refers to the number of mixture components to fit. `mu0`, `Sigma0`, and `pi0`\n",
    "    are initial parameters (automatically set when unspecified).\n",
    "\n",
    "    \"\"\"\n",
    "    N, D = X.shape\n",
    "\n",
    "    if mu0 is None:\n",
    "        mu0 = [np.random.randn(D) for k in range(K)]\n",
    "    if Sigma0 is None:\n",
    "        Sigma0 = [np.eye(D) * 10 for k in range(K)]\n",
    "    if pi0 is None:\n",
    "        pi0 = np.ones(K) / K\n",
    "\n",
    "    model = dict(mu=mu0, Sigma=Sigma0, pi=pi0)\n",
    "    for it in range(max_iter):\n",
    "        W = gmm_e(X, model)\n",
    "        model = gmm_m(X, W)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0389b48c",
   "metadata": {},
   "source": [
    "## 2d+2e) Experiment with GMMs for the toy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca379a1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fit on toy data and color each point by most likely component. Also try fitting with 4\n",
    "# or 6 components.\n",
    "toy_gmm_fit = gmm_fit(toy_gmm[\"X\"], 5)\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb87ae66",
   "metadata": {},
   "source": [
    "## 2f) Discover the Secret (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50434da",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the secret data.\n",
    "X = np.loadtxt(\"data/secret_gmm.csv\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3497a3",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# How many components are hidden in this data?"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
