{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38155495",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.random\n",
    "import numpy.linalg\n",
    "import scipy.io\n",
    "import scipy.stats\n",
    "import sklearn.metrics\n",
    "\n",
    "# setup plotting \n",
    "from IPython import get_ipython\n",
    "import psutil\n",
    "inTerminal = not \"IPKernelApp\" in get_ipython().config\n",
    "inJupyterNb = any(filter(lambda x: x.endswith(\"jupyter-notebook\"), psutil.Process().parent().cmdline()))\n",
    "get_ipython().run_line_magic(\"matplotlib\", \"\" if inTerminal else \"notebook\" if inJupyterNb else \"widget\")\n",
    "def nextplot():\n",
    "    if inTerminal:\n",
    "        plt.clf()     # this clears the current plot\n",
    "    else:\n",
    "        plt.figure()  # this creates a new plot "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6927266",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d29b069",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = scipy.io.loadmat(\"data/spamData.mat\")\n",
    "X = data[\"Xtrain\"]\n",
    "N = X.shape[0]\n",
    "D = X.shape[1]\n",
    "Xtest = data[\"Xtest\"]\n",
    "Ntest = Xtest.shape[0]\n",
    "y = data[\"ytrain\"].squeeze().astype(int)\n",
    "ytest = data[\"ytest\"].squeeze().astype(int)\n",
    "\n",
    "features = np.array(\n",
    "    [\n",
    "        \"word_freq_make\",\n",
    "        \"word_freq_address\",\n",
    "        \"word_freq_all\",\n",
    "        \"word_freq_3d\",\n",
    "        \"word_freq_our\",\n",
    "        \"word_freq_over\",\n",
    "        \"word_freq_remove\",\n",
    "        \"word_freq_internet\",\n",
    "        \"word_freq_order\",\n",
    "        \"word_freq_mail\",\n",
    "        \"word_freq_receive\",\n",
    "        \"word_freq_will\",\n",
    "        \"word_freq_people\",\n",
    "        \"word_freq_report\",\n",
    "        \"word_freq_addresses\",\n",
    "        \"word_freq_free\",\n",
    "        \"word_freq_business\",\n",
    "        \"word_freq_email\",\n",
    "        \"word_freq_you\",\n",
    "        \"word_freq_credit\",\n",
    "        \"word_freq_your\",\n",
    "        \"word_freq_font\",\n",
    "        \"word_freq_000\",\n",
    "        \"word_freq_money\",\n",
    "        \"word_freq_hp\",\n",
    "        \"word_freq_hpl\",\n",
    "        \"word_freq_george\",\n",
    "        \"word_freq_650\",\n",
    "        \"word_freq_lab\",\n",
    "        \"word_freq_labs\",\n",
    "        \"word_freq_telnet\",\n",
    "        \"word_freq_857\",\n",
    "        \"word_freq_data\",\n",
    "        \"word_freq_415\",\n",
    "        \"word_freq_85\",\n",
    "        \"word_freq_technology\",\n",
    "        \"word_freq_1999\",\n",
    "        \"word_freq_parts\",\n",
    "        \"word_freq_pm\",\n",
    "        \"word_freq_direct\",\n",
    "        \"word_freq_cs\",\n",
    "        \"word_freq_meeting\",\n",
    "        \"word_freq_original\",\n",
    "        \"word_freq_project\",\n",
    "        \"word_freq_re\",\n",
    "        \"word_freq_edu\",\n",
    "        \"word_freq_table\",\n",
    "        \"word_freq_conference\",\n",
    "        \"char_freq_;\",\n",
    "        \"char_freq_(\",\n",
    "        \"char_freq_[\",\n",
    "        \"char_freq_!\",\n",
    "        \"char_freq_$\",\n",
    "        \"char_freq_#\",\n",
    "        \"capital_run_length_average\",\n",
    "        \"capital_run_length_longest\",\n",
    "        \"capital_run_length_total\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ee00cf",
   "metadata": {},
   "source": [
    "# 1. Dataset Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4127af74",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# look some dataset statistics\n",
    "scipy.stats.describe(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc04d52",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scipy.stats.describe(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe7f627",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot the distribution of all features\n",
    "nextplot()\n",
    "densities = [scipy.stats.gaussian_kde(X[:, j]) for j in range(D)]\n",
    "xs = np.linspace(0, np.max(X), 200)\n",
    "for j in range(D):\n",
    "    plt.plot(xs, densities[j](xs), label=j)\n",
    "plt.legend(ncol=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0be392f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this plots is not really helpful; go now explore further\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b56c27",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's compute z-scores; create two new variables Xz and Xtestz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36f9864",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's check. Xz and Xtestz refer to the normalized datasets just created. We\n",
    "# will use them throughout.\n",
    "np.mean(Xz, axis=0)  # should be all 0\n",
    "np.var(Xz, axis=0)  # should be all 1\n",
    "np.mean(Xtestz, axis=0)  # what do you get here?\n",
    "np.var(Xtestz, axis=0)\n",
    "\n",
    "np.sum(Xz ** 3)  # should be: 1925261.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590d4b12",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Explore the normalized data\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b16cebd",
   "metadata": {},
   "source": [
    "# 2. Maximum Likelihood Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6a921d",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4a9fcd",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def logsumexp(x):\n",
    "    \"\"\"Computes log(sum(exp(x)).\n",
    "\n",
    "    Uses offset trick to reduce risk of numeric over- or underflow. When x is a\n",
    "    1D ndarray, computes logsumexp of its entries. When x is a 2D ndarray,\n",
    "    computes logsumexp of each column.\n",
    "\n",
    "    Keyword arguments:\n",
    "    x : a 1D or 2D ndarray\n",
    "    \"\"\"\n",
    "    offset = np.max(x, axis=0)\n",
    "    return offset + np.log(np.sum(np.exp(x - offset), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f068e0d3",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the logistic function. Make sure it operates on both scalars\n",
    "# and vectors.\n",
    "def sigma(x):\n",
    "    # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43b2aca",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this should give:\n",
    "# [0.5, array([0.26894142, 0.5, 0.73105858])]\n",
    "[sigma(0), sigma(np.array([-1, 0, 1]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75716619",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the logarithm of the logistic function. Make sure it operates on both\n",
    "# scalars and vectors. Perhaps helpful: isinstance(x, np.ndarray).\n",
    "def logsigma(x):\n",
    "    # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c6bf3d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this should give:\n",
    "# [-0.69314718055994529, array([-1.31326169, -0.69314718, -0.31326169])]\n",
    "[logsigma(0), logsigma(np.array([-1, 0, 1]))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234ebca4",
   "metadata": {},
   "source": [
    "## 2b Log-likelihood and gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3901f99",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def l(y, X, w):\n",
    "    \"\"\"Log-likelihood of the logistic regression model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y : ndarray of shape (N,)\n",
    "        Binary labels (either 0 or 1).\n",
    "    X : ndarray of shape (N,D)\n",
    "        Design matrix.\n",
    "    w : ndarray of shape (D,)\n",
    "        Weight vector.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e25bab",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this should give:\n",
    "# -47066.641667825766\n",
    "l(y, Xz, np.linspace(-5, 5, D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef7aaca",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dl(y, X, w):\n",
    "    \"\"\"Gradient of the log-likelihood of the logistic regression model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y : ndarray of shape (N,)\n",
    "        Binary labels (either 0 or 1).\n",
    "    X : ndarray of shape (N,D)\n",
    "        Design matrix.\n",
    "    w : ndarray of shape (D,)\n",
    "        Weight vector.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ndarray of shape (D,)\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d556a2f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this should give:\n",
    "# array([  551.33985842,   143.84116318,   841.83373606,   156.87237578,\n",
    "#          802.61217579,   795.96202907,   920.69045803,   621.96516752,\n",
    "#          659.18724769,   470.81259805,   771.32406968,   352.40325626,\n",
    "#          455.66972482,   234.36600888,   562.45454038,   864.83981264,\n",
    "#          787.19723703,   649.48042176,   902.6478154 ,   544.00539886,\n",
    "#         1174.78638035,   120.3598967 ,   839.61141672,   633.30453444,\n",
    "#         -706.66815087,  -630.2039816 ,  -569.3451386 ,  -527.50996698,\n",
    "#         -359.53701083,  -476.64334832,  -411.60620464,  -375.11950586,\n",
    "#         -345.37195689,  -376.22044258,  -407.31761977,  -456.23251936,\n",
    "#         -596.86960184,  -107.97072355,  -394.82170044,  -229.18125598,\n",
    "#         -288.46356547,  -362.13402385,  -450.87896465,  -277.03932676,\n",
    "#         -414.99293368,  -452.28771693,  -167.54649092,  -270.9043748 ,\n",
    "#         -252.20140951,  -357.72497343,  -259.12468742,   418.35938483,\n",
    "#          604.54173228,    43.10390907,   152.24258478,   378.16731033,\n",
    "#          416.12032881])\n",
    "dl(y, Xz, np.linspace(-5, 5, D))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd228144",
   "metadata": {},
   "source": [
    "## 2c Gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d712749e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# you don't need to modify this function\n",
    "def optimize(obj_up, theta0, nepochs=50, eps0=0.01, verbose=True):\n",
    "    \"\"\"Iteratively minimize a function.\n",
    "\n",
    "    We use it here to run either gradient descent or stochastic gradient\n",
    "    descent, using arbitrarly optimization criteria.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    obj_up  : a tuple of form (f, update) containing two functions f and update.\n",
    "              f(theta) computes the value of the objective function.\n",
    "              update(theta,eps) performs an epoch of parameter update with step size\n",
    "              eps and returns the result.\n",
    "    theta0  : ndarray of shape (D,)\n",
    "              Initial parameter vector.\n",
    "    nepochs : int\n",
    "              How many epochs (calls to update) to run.\n",
    "    eps0    : float\n",
    "              Initial step size.\n",
    "    verbose : boolean\n",
    "              Whether to print progress information.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A triple consisting of the fitted parameter vector, the values of the\n",
    "    objective function after every epoch, and the step sizes that were used.\n",
    "    \"\"\"\n",
    "\n",
    "    f, update = obj_up\n",
    "\n",
    "    # initialize results\n",
    "    theta = theta0\n",
    "    values = np.zeros(nepochs + 1)\n",
    "    eps = np.zeros(nepochs + 1)\n",
    "    values[0] = f(theta0)\n",
    "    eps[0] = eps0\n",
    "\n",
    "    # now run the update function nepochs times\n",
    "    for epoch in range(nepochs):\n",
    "        if verbose:\n",
    "            print(\n",
    "                \"Epoch {:3d}: f={:10.3f}, eps={:10.9f}\".format(\n",
    "                    epoch, values[epoch], eps[epoch]\n",
    "                )\n",
    "            )\n",
    "        theta = update(theta, eps[epoch])\n",
    "\n",
    "        # we use the bold driver heuristic\n",
    "        values[epoch + 1] = f(theta)\n",
    "        if values[epoch] < values[epoch + 1]:\n",
    "            eps[epoch + 1] = eps[epoch] / 2.0\n",
    "        else:\n",
    "            eps[epoch + 1] = eps[epoch] * 1.05\n",
    "\n",
    "    # all done\n",
    "    if verbose:\n",
    "        print(\"Result after {} epochs: f={}\".format(nepochs, values[-1]))\n",
    "    return theta, values, eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e119de",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define the objective and update function for one gradient-descent epoch for\n",
    "# fitting an MLE estimate of logistic regression with gradient descent (should\n",
    "# return a tuple of two functions; see optimize)\n",
    "def gd(y, X):\n",
    "    def objective(w):\n",
    "        # YOUR CODE HERE\n",
    "\n",
    "    def update(w, eps):\n",
    "        # YOUR CODE HERE\n",
    "\n",
    "    return (objective, update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f87184",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this should give\n",
    "# [47066.641667825766,\n",
    "#  array([  4.13777838e+01,  -1.56745627e+01,   5.75882538e+01,\n",
    "#           1.14225143e+01,   5.54249703e+01,   5.99229049e+01,\n",
    "#           7.11220141e+01,   4.84761728e+01,   5.78067289e+01,\n",
    "#           4.54794720e+01,   7.14638492e+01,   1.51369386e+01,\n",
    "#           3.36375739e+01,   2.15061217e+01,   5.78014255e+01,\n",
    "#           6.72743066e+01,   7.00829312e+01,   5.29328088e+01,\n",
    "#           6.16042473e+01,   5.50018510e+01,   8.94624817e+01,\n",
    "#           2.74784480e+01,   8.51763599e+01,   5.60363965e+01,\n",
    "#          -2.55865589e+01,  -1.53788213e+01,  -4.67015412e+01,\n",
    "#          -2.50356570e+00,  -3.85357592e+00,  -2.21819155e+00,\n",
    "#           3.32098671e+00,   3.86933390e+00,  -2.00309898e+01,\n",
    "#           3.84684492e+00,  -2.19847927e-01,  -1.29775457e+00,\n",
    "#          -1.28374302e+01,  -2.78303173e+00,  -5.61671182e+00,\n",
    "#           1.73657121e+01,  -6.81197570e+00,  -1.20249002e+01,\n",
    "#           2.65789491e+00,  -1.39557852e+01,  -2.01135653e+01,\n",
    "#          -2.72134051e+01,  -9.45952961e-01,  -1.02239111e+01,\n",
    "#           1.52794293e-04,  -5.18938123e-01,  -3.19717561e+00,\n",
    "#           4.62953437e+01,   7.87893022e+01,   1.88618651e+01,\n",
    "#           2.85195027e+01,   5.04698358e+01,   6.41240689e+01])\n",
    "f, update = gd(y, Xz)\n",
    "[f(np.linspace(-5, 5, D)), update(np.linspace(-5, -5, D), 0.1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde01365",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# you can run gradient descent!\n",
    "numpy.random.seed(0)\n",
    "w0 = np.random.normal(size=D)\n",
    "wz_gd, vz_gd, ez_gd = optimize(gd(y, Xz), w0, nepochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c75cbd0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# look at how gradient descent made progess\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e291580",
   "metadata": {},
   "source": [
    "## 2d Stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2d9e1d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sgdepoch(y, X, w, eps):\n",
    "    \"\"\"Run one SGD epoch and return the updated weight vector. \"\"\"\n",
    "    # Run N stochastic gradient steps (without replacement). Do not rescale each\n",
    "    # step by factor N (i.e., proceed differently than in the lecture slides).\n",
    "    # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c70f6f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# when you run this multiple times, with 50% probability you should get the\n",
    "# following result (there is one other result which is very close):\n",
    "# array([ -3.43689655e+02,  -1.71161311e+02,  -5.71093536e+02,\n",
    "#         -5.16478220e+01,   4.66294348e+02,  -3.71589878e+02,\n",
    "#          5.21493183e+02,   1.25699230e+03,   8.33804130e+02,\n",
    "#          5.63185399e+02,   1.32761302e+03,  -2.64104011e+02,\n",
    "#          7.10693307e+02,  -1.75497331e+02,  -1.94174427e+02,\n",
    "#          1.11641507e+02,  -3.30817509e+02,  -3.46754913e+02,\n",
    "#          8.48722111e+02,  -1.89136304e+02,  -4.25693844e+02,\n",
    "#         -1.23084189e+02,  -2.95894797e+02,  -2.35789333e+02,\n",
    "#         -3.38695243e+02,  -3.05642830e+02,  -2.28975383e+02,\n",
    "#         -2.38075137e+02,  -1.66702530e+02,  -2.27341599e+02,\n",
    "#         -1.77575620e+02,  -1.49093855e+02,  -1.70028859e+02,\n",
    "#         -1.50243833e+02,  -1.82986008e+02,  -2.41143708e+02,\n",
    "#         -3.31047159e+02,  -5.79991185e+01,  -1.98477863e+02,\n",
    "#         -1.91264948e+02,  -1.17371919e+02,  -1.66953779e+02,\n",
    "#         -2.01472565e+02,  -1.23330949e+02,  -3.00857740e+02,\n",
    "#         -1.95853348e+02,  -7.44868073e+01,  -1.11172370e+02,\n",
    "#         -1.57618226e+02,  -1.25729512e+00,  -1.45536466e+02,\n",
    "#         -1.43362438e+02,  -3.00429708e+02,  -9.84391082e+01,\n",
    "#         -4.54152047e+01,  -5.26492232e+01,  -1.45175427e+02])\n",
    "sgdepoch(y[1:3], Xz[1:3, :], np.linspace(-5, 5, D), 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2b71aa",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define the objective and update function for one gradient-descent epoch for\n",
    "# fitting an MLE estimate of logistic regression with stochastic gradient descent\n",
    "# (should return a tuple of two functions; see optimize)\n",
    "def sgd(y, X):\n",
    "    def objective(w):\n",
    "        # YOUR CODE HERE\n",
    "\n",
    "    def update(w, eps):\n",
    "        return sgdepoch(y, X, w, eps)\n",
    "\n",
    "    return (objective, update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579be14f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# with 50% probability, you should get:\n",
    "# [40.864973045695081,\n",
    "#  array([ -3.43689655e+02,  -1.71161311e+02,  -5.71093536e+02,\n",
    "#          -5.16478220e+01,   4.66294348e+02,  -3.71589878e+02,\n",
    "#           5.21493183e+02,   1.25699230e+03,   8.33804130e+02,\n",
    "#           5.63185399e+02,   1.32761302e+03,  -2.64104011e+02,\n",
    "#           7.10693307e+02,  -1.75497331e+02,  -1.94174427e+02,\n",
    "#           1.11641507e+02,  -3.30817509e+02,  -3.46754913e+02,\n",
    "#           8.48722111e+02,  -1.89136304e+02,  -4.25693844e+02,\n",
    "#          -1.23084189e+02,  -2.95894797e+02,  -2.35789333e+02,\n",
    "#          -3.38695243e+02,  -3.05642830e+02,  -2.28975383e+02,\n",
    "#          -2.38075137e+02,  -1.66702530e+02,  -2.27341599e+02,\n",
    "#          -1.77575620e+02,  -1.49093855e+02,  -1.70028859e+02,\n",
    "#          -1.50243833e+02,  -1.82986008e+02,  -2.41143708e+02,\n",
    "#          -3.31047159e+02,  -5.79991185e+01,  -1.98477863e+02,\n",
    "#          -1.91264948e+02,  -1.17371919e+02,  -1.66953779e+02,\n",
    "#          -2.01472565e+02,  -1.23330949e+02,  -3.00857740e+02,\n",
    "#          -1.95853348e+02,  -7.44868073e+01,  -1.11172370e+02,\n",
    "#          -1.57618226e+02,  -1.25729512e+00,  -1.45536466e+02,\n",
    "#          -1.43362438e+02,  -3.00429708e+02,  -9.84391082e+01,\n",
    "#          -4.54152047e+01,  -5.26492232e+01,  -1.45175427e+02])]\n",
    "f, update = sgd(y[1:3], Xz[1:3, :])\n",
    "[f(np.linspace(-5, 5, D)), update(np.linspace(-5, 5, D), 1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555839f4",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# you can run stochastic gradient descent!\n",
    "wz_sgd, vz_sgd, ez_sgd = optimize(sgd(y, Xz), w0, nepochs=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969495d6",
   "metadata": {},
   "source": [
    "## 2e Compare GD and SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa9d3c8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05acb506",
   "metadata": {},
   "source": [
    "# 3 Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54368f0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict(Xtest, w):\n",
    "    \"\"\"Returns vector of predicted confidence values for logistic regression with\n",
    "weight vector w.\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "\n",
    "def classify(Xtest, w):\n",
    "    \"\"\"Returns 0/1 vector of predicted class labels for logistic regression with\n",
    "weight vector w.\"\"\"\n",
    "    # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44705a32",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Example: confusion matrix\n",
    "yhat = predict(Xtestz, wz_gd)\n",
    "ypred = classify(Xtestz, wz_gd)\n",
    "print(sklearn.metrics.confusion_matrix(ytest, ypred))  # true x predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8ecaa9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Example: classification report\n",
    "print(sklearn.metrics.classification_report(ytest, ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6d7a30",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Example: precision-recall curve (with annotated thresholds)\n",
    "nextplot()\n",
    "precision, recall, thresholds = sklearn.metrics.precision_recall_curve(ytest, yhat)\n",
    "plt.plot(recall, precision)\n",
    "for x in np.linspace(0, 1, 10, endpoint=False):\n",
    "    index = int(x * (precision.size - 1))\n",
    "    plt.text(recall[index], precision[index], \"{:3.2f}\".format(thresholds[index]))\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98fdf3a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Explore which features are considered important\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d55b32",
   "metadata": {},
   "source": [
    "# 4 Maximum Aposteriori Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eeb1e0f",
   "metadata": {},
   "source": [
    "## 4a Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae615b89",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def l_l2(y, X, w, lambda_):\n",
    "    \"\"\"Log-density of posterior of logistic regression with weights w and L2\n",
    "regularization parameter lambda_\"\"\"\n",
    "    # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0817df",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this should give:\n",
    "# [-47066.641667825766, -47312.623810682911]\n",
    "[l_l2(y, Xz, np.linspace(-5, 5, D), 0), l_l2(y, Xz, np.linspace(-5, 5, D), 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf11375d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dl_l2(y, X, w, lambda_):\n",
    "    \"\"\"Gradient of log-density of posterior of logistic regression with weights w\n",
    "and L2 regularization parameter lambda_.\"\"\"\n",
    "    # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb2cced",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this should give:\n",
    "# [array([  551.33985842,   143.84116318,   841.83373606,   156.87237578,\n",
    "#           802.61217579,   795.96202907,   920.69045803,   621.96516752,\n",
    "#           659.18724769,   470.81259805,   771.32406968,   352.40325626,\n",
    "#           455.66972482,   234.36600888,   562.45454038,   864.83981264,\n",
    "#           787.19723703,   649.48042176,   902.6478154 ,   544.00539886,\n",
    "#          1174.78638035,   120.3598967 ,   839.61141672,   633.30453444,\n",
    "#          -706.66815087,  -630.2039816 ,  -569.3451386 ,  -527.50996698,\n",
    "#          -359.53701083,  -476.64334832,  -411.60620464,  -375.11950586,\n",
    "#          -345.37195689,  -376.22044258,  -407.31761977,  -456.23251936,\n",
    "#          -596.86960184,  -107.97072355,  -394.82170044,  -229.18125598,\n",
    "#          -288.46356547,  -362.13402385,  -450.87896465,  -277.03932676,\n",
    "#          -414.99293368,  -452.28771693,  -167.54649092,  -270.9043748 ,\n",
    "#          -252.20140951,  -357.72497343,  -259.12468742,   418.35938483,\n",
    "#           604.54173228,    43.10390907,   152.24258478,   378.16731033,\n",
    "#           416.12032881]),\n",
    "#  array([  556.33985842,   148.66259175,   846.4765932 ,   161.33666149,\n",
    "#           806.89789007,   800.06917193,   924.61902946,   625.71516752,\n",
    "#           662.75867626,   474.20545519,   774.5383554 ,   355.43897054,\n",
    "#           458.52686767,   237.04458031,   564.95454038,   867.16124121,\n",
    "#           789.34009417,   651.44470748,   904.43352968,   545.61254171,\n",
    "#          1176.21495178,   121.6098967 ,   840.68284529,   634.19739158,\n",
    "#          -705.95386516,  -629.66826731,  -568.98799574,  -527.33139555,\n",
    "#          -359.53701083,  -476.82191975,  -411.9633475 ,  -375.65522015,\n",
    "#          -346.08624261,  -377.11329972,  -408.38904835,  -457.48251936,\n",
    "#          -598.29817327,  -109.57786641,  -396.60741472,  -231.14554169,\n",
    "#          -290.60642261,  -364.45545242,  -453.37896465,  -279.71789819,\n",
    "#          -417.85007654,  -455.32343122,  -170.76077664,  -274.29723194,\n",
    "#          -255.77283808,  -361.47497343,  -263.05325885,   414.25224198,\n",
    "#           600.25601799,    38.63962335,   147.59972763,   373.34588176,\n",
    "#           411.12032881])]\n",
    "[dl_l2(y, Xz, np.linspace(-5, 5, D), 0), dl_l2(y, Xz, np.linspace(-5, 5, D), 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030554c9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now define the (f,update) tuple for optimize for logistic regression, L2\n",
    "# regularization, and gradient descent\n",
    "def gd_l2(y, X, lambda_):\n",
    "    # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1fddaf",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's run!\n",
    "lambda_ = 100\n",
    "wz_gd_l2, vz_gd_l2, ez_gd_l2 = optimize(gd_l2(y, Xz, lambda_), w0, nepochs=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e951b36",
   "metadata": {},
   "source": [
    "## 4b Effect of Prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebb035f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62aa213f",
   "metadata": {},
   "source": [
    "## 4c Composition of Weight Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2fa843",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567ae6b8",
   "metadata": {},
   "source": [
    "## 5 Exploration (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea23bfaf",
   "metadata": {},
   "source": [
    "### 5 Exploration: PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2816ac6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# if you want to experiment, here is an implementation of logistic\n",
    "# regression in PyTorch\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# prepare the data\n",
    "Xztorch = torch.FloatTensor(Xz)\n",
    "ytorch = torch.LongTensor(y)\n",
    "train = torch.utils.data.TensorDataset(Xztorch, ytorch)\n",
    "\n",
    "\n",
    "# manual implementation of logistic regression (without bias)\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, D, C):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.weights = torch.nn.Parameter(\n",
    "            torch.randn(D, C) / math.sqrt(D)\n",
    "        )  # xavier initialization\n",
    "        self.register_parameter(\"W\", self.weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.matmul(x, self.weights)\n",
    "        out = F.log_softmax(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "# define the objective and update function. here we ignore the learning rates\n",
    "# and parameters given to us by optimize (they are stored in the PyTorch model\n",
    "# and optimizer, resp., instead)\n",
    "def opt_pytorch():\n",
    "    model = LogisticRegression(D, 2)\n",
    "    criterion = nn.NLLLoss(reduction=\"sum\")\n",
    "    # change the next line to try different optimizers\n",
    "    # optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    def objective(_):\n",
    "        outputs = model(Xztorch)\n",
    "        return criterion(outputs, ytorch)\n",
    "\n",
    "    def update(_1, _2):\n",
    "        for i, (examples, labels) in enumerate(train_loader):\n",
    "            outputs = model(examples)\n",
    "            loss = criterion(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        W = model.state_dict()[\"W\"]\n",
    "        w = W[:, 1] - W[:, 0]\n",
    "        return w\n",
    "\n",
    "    return (objective, update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7816a8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# run the optimizer\n",
    "learning_rate = 0.01\n",
    "batch_size = 100  # number of data points to sample for gradient estimate\n",
    "shuffle = True  # sample with replacement (false) or without replacement (true)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size, shuffle=True)\n",
    "wz_t, vz_t, _ = optimize(opt_pytorch(), None, nepochs=100, eps0=None, verbose=True)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
